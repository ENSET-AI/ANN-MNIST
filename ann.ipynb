{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X: np.ndarray = digits[\"data\"]\n",
    "Y: np.ndarray = digits[\"target\"]\n",
    "\n",
    "L, C = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = encodeY(Y[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Normalizer().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "C = X_train.shape[1]\n",
    "n_hidden1 = 16\n",
    "n_hidden2 = 16\n",
    "n_output = 10\n",
    "\n",
    "w1 = np.random.randn(C + 1, n_hidden1) * np.sqrt(2.0 / (C + 1))\n",
    "w2 = np.random.randn(n_hidden1 + 1, n_hidden2) * np.sqrt(2.0 / (n_hidden1 + 1))\n",
    "w3 = np.random.randn(n_hidden2 + 1, n_output) * np.sqrt(2.0 / (n_hidden2 + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## **Input**\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_{0} & x_{1} & \\cdots & x_{63} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## **Output**\n",
    "\n",
    "$$\n",
    "Y = \\begin{bmatrix}\n",
    "y_{0} & y_{1} & \\cdots & y_{9} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## **Model**\n",
    "\n",
    "The model consists of 3 layers.\n",
    "\n",
    "### Layer 1\n",
    "\n",
    "$$\n",
    "W^{(1)} =\n",
    "\\begin{bmatrix}\n",
    "w_{00} & \\cdots & w_{0,15} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "w_{64,0} & \\cdots & w_{64,15} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Dimensions:** $W^{(1)} \\in \\mathbb{R}^{65 \\times 16}$  \n",
    "  (The input $X$ has 64 features and we add a bias term, resulting in 65 inputs.)\n",
    "- **Neurons:** There are 16 neurons in this layer.\n",
    "\n",
    "### Layer 2\n",
    "\n",
    "$$\n",
    "W^{(2)} \\in \\mathbb{R}^{17 \\times 16}\n",
    "$$\n",
    "\n",
    "- **Dimensions:** Each neuron in Layer 2 receives 16 outputs from Layer 1 plus a bias term, totaling 17 inputs.\n",
    "- **Neurons:** There are 16 neurons in this layer.\n",
    "\n",
    "### Layer 3 (Output Layer)\n",
    "\n",
    "$$\n",
    "W^{(3)} \\in \\mathbb{R}^{17 \\times 10}\n",
    "$$\n",
    "\n",
    "- **Dimensions:** Each neuron in Layer 3 receives 16 outputs from Layer 2 plus a bias term, totaling 17 inputs.\n",
    "- **Neurons:** There are 10 neurons in this layer, corresponding to the output vector $Y$.\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "The activation function used in all layers is ReLU:\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "### Forward Pass Equations\n",
    "\n",
    "The forward propagation through the network is given by:\n",
    "\n",
    "1. **Layer 1:**\n",
    "   $$\n",
    "   z^{(1)} = X \\cdot W^{(1)} + b^{(1)}\n",
    "   $$\n",
    "   $$\n",
    "   a^{(1)} = \\text{ReLU}(z^{(1)})\n",
    "   $$\n",
    "\n",
    "2. **Layer 2:**\n",
    "   $$\n",
    "   z^{(2)} = a^{(1)} \\cdot W^{(2)} + b^{(2)}\n",
    "   $$\n",
    "   $$\n",
    "   a^{(2)} = \\text{ReLU}(z^{(2)})\n",
    "   $$\n",
    "\n",
    "3. **Layer 3 (Output Layer):**\n",
    "   $$\n",
    "   z^{(3)} = a^{(2)} \\cdot W^{(3)} + b^{(3)}\n",
    "   $$\n",
    "   $$\n",
    "   \\hat{Y} = a^{(3)} = \\text{ReLU}(z^{(3)})\n",
    "   $$ -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Loss-Function\n",
    "\n",
    "$$J = \\frac{1}{2n} \\sum (\\hat{Y} - Y)^{2} $$\n",
    "\n",
    "## Back-propagation\n",
    "\n",
    "$$\n",
    "W^{(i)} \\leftarrow W^{(i)} - \\alpha \\cdot \\frac{\\partial J}{\\partial W^{(i)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{(i)} \\leftarrow b^{(i)} - \\alpha \\cdot \\frac{\\partial J}{\\partial b^{(i)}}\n",
    "$$\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Third Layer\n",
    "\n",
    "we must find:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(3)}}\n",
    "= \\frac{\\partial J}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial W^{(3)}} \\\\\n",
    "=\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} \\cdot\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial W^{(3)}} \\\\ =\n",
    "\\frac{1}{n} \\sum (\\hat{Y} - Y) \\odot\n",
    "1 (z^{(3)} > 0) \\cdot\n",
    "a^{(2)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b^{(3)}} =\n",
    "\\frac{\\partial J}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial b^{(3)}} \\\\=\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} \\cdot\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial b^{(3)}} \\\\=\n",
    "\\frac{1}{n} \\sum (\\hat{Y} - Y) \\odot\n",
    "1 (z^{(3)} > 0)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "J = \\frac{1}{2n} \\sum (\\hat{Y} - Y)^{2} \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} =  \\frac{1}{n} \\sum (\\hat{Y} - Y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{Y} = a^{(3)} = \\text{ReLU}(z^{(3)}) \\\\\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} =  1 (z^{(3)} > 0) \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "z^{(3)} = a^{(2)} \\cdot W^{(3)} + b^{(3)} \\\\\n",
    "\\frac{\\partial z^{(3)}}{\\partial W^{(3)}} = a^{(2)} \\\\\n",
    "\\frac{\\partial z^{(3)}}{\\partial b^{(3)}} = 1\n",
    "$$ -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Second Layer\n",
    "\n",
    "we must find:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(2)}} \\\\=\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} \\cdot\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\cdot\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial W^{(2)}} \\\\=\n",
    "\n",
    "\\frac{\\partial J}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\cdot\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial W^{(2)}}\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b^{(2)}} \\\\=\n",
    "\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} \\cdot\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\cdot\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial b^{(2)}} \\\\=\n",
    "\n",
    "\\frac{\\partial J}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\cdot\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial b^{(2)}}\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} = W^{(3)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} = 1 (z^{(2)} > 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(2)}}{\\partial W^{(2)}} = a^{(1)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(2)}}{\\partial b^{(2)}} = 1\n",
    "$$ -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### First Layer\n",
    "\n",
    "we must find:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} \\\\ =\n",
    "\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} \\cdot\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\cdot\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial a^{(1)}} \\cdot\n",
    "\\frac{\\partial a^{(1)}}{\\partial z^{(1)}} \\cdot\n",
    "\\frac{\\partial z^{(1)}}{\\partial W^{(1)}} \\\\ =\n",
    "\n",
    "\\frac{\\partial J}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial a^{(1)}} \\cdot\n",
    "\\frac{\\partial a^{(1)}}{\\partial z^{(1)}} \\cdot\n",
    "\\frac{\\partial z^{(1)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b^{(1)}} \\\\=\n",
    "\n",
    "\\frac{\\partial J}{\\partial \\hat{Y}} \\cdot\n",
    "\\frac{\\partial \\hat{Y}}{\\partial z^{(3)}} \\cdot\n",
    "\\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\cdot\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial a^{(1)}} \\cdot\n",
    "\\frac{\\partial a^{(1)}}{\\partial z^{(1)}} \\cdot\n",
    "\\frac{\\partial z^{(1)}}{\\partial b^{(1)}} \\\\=\n",
    "\n",
    "\\frac{\\partial J}{\\partial z^{(2)}} \\cdot\n",
    "\\frac{\\partial z^{(2)}}{\\partial a^{(1)}} \\cdot\n",
    "\\frac{\\partial a^{(1)}}{\\partial z^{(1)}} \\cdot\n",
    "\\frac{\\partial z^{(1)}}{\\partial b^{(1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(2)}}{\\partial a^{(1)}} = W^{(2)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a^{(1)}}{\\partial z^{(1)}} = 1 (z^{(1)} > 1)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial z^{(1)}}{\\partial W^{(1)}} = X\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial z^{(1)}}{\\partial b^{(1)}} = 1\n",
    "$$ -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "errs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permutation = np.random.permutation(len(X_train))\n",
    "    X_shuffled = X_train[permutation]\n",
    "    y_shuffled = y_train[permutation]\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_shuffled[i : i + batch_size]\n",
    "        y_batch = y_shuffled[i : i + batch_size]\n",
    "\n",
    "        z1 = add_bias(X_batch).dot(w1)\n",
    "        a1 = reLU(z1)\n",
    "\n",
    "        z2 = add_bias(a1).dot(w2)\n",
    "        a2 = reLU(z2)\n",
    "\n",
    "        z3 = add_bias(a2).dot(w3)\n",
    "        a3 = softmax(z3)\n",
    "\n",
    "        loss = cross_entropy_loss(a3, y_batch)\n",
    "        total_loss += loss\n",
    "\n",
    "        delta3: np.ndarray = (a3 - y_batch) / batch_size\n",
    "        gradient_w3: np.ndarray = add_bias(a2).T.dot(delta3)\n",
    "\n",
    "        delta2: np.ndarray = (delta3.dot(w3[:-1].T)) * get_gradient_reLU(z2)\n",
    "        gradient_w2: np.ndarray = add_bias(a1).T.dot(delta2)\n",
    "\n",
    "        delta1: np.ndarray = (delta2.dot(w2[:-1].T)) * get_gradient_reLU(z1)\n",
    "        gradient_w1: np.ndarray = add_bias(X_batch).T.dot(delta1)\n",
    "\n",
    "        w3 -= alpha * gradient_w3\n",
    "        w2 -= alpha * gradient_w2\n",
    "        w1 -= alpha * gradient_w1\n",
    "\n",
    "    avg_loss = total_loss / (len(X_train) // batch_size)\n",
    "    errs.append(avg_loss)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_test, w1, w2, w3)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
